number of tree 1 at positions  [(0, 9)] at Config 0 at episode 0 with total number of rewards: 13, total steps83, the average reward per action: 0.15662650602390768, and difference between optimal steps and model steps are 61
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 1 with total number of rewards: 3, total steps100, the average reward per action: 0.02999999999997, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 2 with total number of rewards: 3, total steps100, the average reward per action: 0.02999999999997, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 3 with total number of rewards: -9, total steps100, the average reward per action: -0.08999999999991, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 4 with total number of rewards: -3, total steps100, the average reward per action: -0.02999999999997, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 5 with total number of rewards: -1, total steps100, the average reward per action: -0.00999999999999, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 6 with total number of rewards: -17, total steps100, the average reward per action: -0.16999999999983, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 7 with total number of rewards: 5, total steps100, the average reward per action: 0.04999999999995, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 8 with total number of rewards: -1, total steps100, the average reward per action: -0.00999999999999, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 9 with total number of rewards: 8, total steps92, the average reward per action: 0.08695652173903591, and difference between optimal steps and model steps are 70
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 10 with total number of rewards: 7, total steps95, the average reward per action: 0.07368421052623822, and difference between optimal steps and model steps are 73
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 11 with total number of rewards: -5, total steps100, the average reward per action: -0.04999999999995, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 12 with total number of rewards: 7, total steps100, the average reward per action: 0.06999999999993, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 13 with total number of rewards: -5, total steps100, the average reward per action: -0.04999999999995, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 14 with total number of rewards: -1, total steps100, the average reward per action: -0.00999999999999, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 15 with total number of rewards: 3, total steps100, the average reward per action: 0.02999999999997, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 16 with total number of rewards: 3, total steps100, the average reward per action: 0.02999999999997, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 17 with total number of rewards: 1, total steps100, the average reward per action: 0.00999999999999, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 18 with total number of rewards: 7, total steps100, the average reward per action: 0.06999999999993, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 19 with total number of rewards: -29, total steps100, the average reward per action: -0.28999999999971, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 20 with total number of rewards: 3, total steps100, the average reward per action: 0.02999999999997, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 21 with total number of rewards: 16, total steps62, the average reward per action: 0.25806451612861603, and difference between optimal steps and model steps are 40
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 22 with total number of rewards: -7, total steps100, the average reward per action: -0.06999999999993, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 23 with total number of rewards: -7, total steps100, the average reward per action: -0.06999999999993, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 24 with total number of rewards: 11, total steps100, the average reward per action: 0.10999999999988999, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 25 with total number of rewards: -1, total steps100, the average reward per action: -0.00999999999999, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 26 with total number of rewards: 3, total steps95, the average reward per action: 0.03157894736838781, and difference between optimal steps and model steps are 73
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 27 with total number of rewards: -1, total steps100, the average reward per action: -0.00999999999999, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 28 with total number of rewards: 11, total steps97, the average reward per action: 0.1134020618555532, and difference between optimal steps and model steps are 75
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 29 with total number of rewards: 9, total steps100, the average reward per action: 0.08999999999991, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 30 with total number of rewards: -3, total steps100, the average reward per action: -0.02999999999997, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 31 with total number of rewards: 14, total steps90, the average reward per action: 0.15555555555538272, and difference between optimal steps and model steps are 68
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 32 with total number of rewards: -15, total steps100, the average reward per action: -0.14999999999985, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 33 with total number of rewards: -1, total steps100, the average reward per action: -0.00999999999999, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 34 with total number of rewards: 17, total steps57, the average reward per action: 0.29824561403456445, and difference between optimal steps and model steps are 35
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 35 with total number of rewards: 19, total steps51, the average reward per action: 0.3725490196071126, and difference between optimal steps and model steps are 29
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 36 with total number of rewards: 9, total steps79, the average reward per action: 0.11392405063276718, and difference between optimal steps and model steps are 57
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 37 with total number of rewards: -1, total steps100, the average reward per action: -0.00999999999999, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 38 with total number of rewards: -17, total steps100, the average reward per action: -0.16999999999983, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 39 with total number of rewards: -5, total steps100, the average reward per action: -0.04999999999995, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 40 with total number of rewards: 7, total steps100, the average reward per action: 0.06999999999993, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 41 with total number of rewards: 13, total steps49, the average reward per action: 0.26530612244843815, and difference between optimal steps and model steps are 27
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 42 with total number of rewards: -15, total steps100, the average reward per action: -0.14999999999985, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 43 with total number of rewards: 11, total steps61, the average reward per action: 0.1803278688521634, and difference between optimal steps and model steps are 39
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 44 with total number of rewards: 9, total steps63, the average reward per action: 0.1428571428569161, and difference between optimal steps and model steps are 41
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 45 with total number of rewards: 3, total steps100, the average reward per action: 0.02999999999997, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 46 with total number of rewards: 7, total steps100, the average reward per action: 0.06999999999993, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 47 with total number of rewards: -3, total steps100, the average reward per action: -0.02999999999997, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 48 with total number of rewards: 16, total steps60, the average reward per action: 0.26666666666622224, and difference between optimal steps and model steps are 38
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 49 with total number of rewards: 1, total steps100, the average reward per action: 0.00999999999999, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 50 with total number of rewards: -3, total steps100, the average reward per action: -0.02999999999997, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 51 with total number of rewards: 7, total steps100, the average reward per action: 0.06999999999993, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 52 with total number of rewards: 3, total steps100, the average reward per action: 0.02999999999997, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 53 with total number of rewards: 17, total steps59, the average reward per action: 0.2881355932198506, and difference between optimal steps and model steps are 37
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 54 with total number of rewards: 12, total steps90, the average reward per action: 0.13333333333318517, and difference between optimal steps and model steps are 68
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 55 with total number of rewards: 9, total steps100, the average reward per action: 0.08999999999991, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 56 with total number of rewards: 15, total steps57, the average reward per action: 0.2631578947363804, and difference between optimal steps and model steps are 35
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 57 with total number of rewards: 1, total steps100, the average reward per action: 0.00999999999999, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 58 with total number of rewards: 13, total steps100, the average reward per action: 0.12999999999987, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 59 with total number of rewards: -15, total steps100, the average reward per action: -0.14999999999985, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 60 with total number of rewards: 5, total steps100, the average reward per action: 0.04999999999995, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 61 with total number of rewards: -3, total steps100, the average reward per action: -0.02999999999997, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 62 with total number of rewards: 8, total steps66, the average reward per action: 0.12121212121193756, and difference between optimal steps and model steps are 44
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 63 with total number of rewards: 11, total steps63, the average reward per action: 0.17460317460289745, and difference between optimal steps and model steps are 41
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 64 with total number of rewards: 13, total steps87, the average reward per action: 0.14942528735615007, and difference between optimal steps and model steps are 65
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 65 with total number of rewards: -1, total steps100, the average reward per action: -0.00999999999999, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 66 with total number of rewards: 16, total steps40, the average reward per action: 0.399999999999, and difference between optimal steps and model steps are 18
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 67 with total number of rewards: 4, total steps88, the average reward per action: 0.0454545454544938, and difference between optimal steps and model steps are 66
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 68 with total number of rewards: 7, total steps95, the average reward per action: 0.07368421052623822, and difference between optimal steps and model steps are 73
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 69 with total number of rewards: -9, total steps100, the average reward per action: -0.08999999999991, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 70 with total number of rewards: 12, total steps66, the average reward per action: 0.18181818181790632, and difference between optimal steps and model steps are 44
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 71 with total number of rewards: 3, total steps100, the average reward per action: 0.02999999999997, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 72 with total number of rewards: -3, total steps100, the average reward per action: -0.02999999999997, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 73 with total number of rewards: -5, total steps93, the average reward per action: -0.05376344086015724, and difference between optimal steps and model steps are 71
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 74 with total number of rewards: 8, total steps86, the average reward per action: 0.09302325581384532, and difference between optimal steps and model steps are 64
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 75 with total number of rewards: 9, total steps100, the average reward per action: 0.08999999999991, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 76 with total number of rewards: 7, total steps100, the average reward per action: 0.06999999999993, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 77 with total number of rewards: 18, total steps32, the average reward per action: 0.5624999999982422, and difference between optimal steps and model steps are 10
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 78 with total number of rewards: 7, total steps100, the average reward per action: 0.06999999999993, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 79 with total number of rewards: 12, total steps76, the average reward per action: 0.1578947368418975, and difference between optimal steps and model steps are 54
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 80 with total number of rewards: -1, total steps100, the average reward per action: -0.00999999999999, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 81 with total number of rewards: -1, total steps100, the average reward per action: -0.00999999999999, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 82 with total number of rewards: -1, total steps100, the average reward per action: -0.00999999999999, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 83 with total number of rewards: 15, total steps69, the average reward per action: 0.21739130434751103, and difference between optimal steps and model steps are 47
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 84 with total number of rewards: 3, total steps100, the average reward per action: 0.02999999999997, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 85 with total number of rewards: 20, total steps80, the average reward per action: 0.2499999999996875, and difference between optimal steps and model steps are 58
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 86 with total number of rewards: 11, total steps65, the average reward per action: 0.16923076923050887, and difference between optimal steps and model steps are 43
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 87 with total number of rewards: 1, total steps100, the average reward per action: 0.00999999999999, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 88 with total number of rewards: 11, total steps69, the average reward per action: 0.1594202898548414, and difference between optimal steps and model steps are 47
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 89 with total number of rewards: 5, total steps100, the average reward per action: 0.04999999999995, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 90 with total number of rewards: -7, total steps100, the average reward per action: -0.06999999999993, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 91 with total number of rewards: 17, total steps61, the average reward per action: 0.27868852458970705, and difference between optimal steps and model steps are 39
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 92 with total number of rewards: 15, total steps63, the average reward per action: 0.23809523809486016, and difference between optimal steps and model steps are 41
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 93 with total number of rewards: 19, total steps47, the average reward per action: 0.40425531914807605, and difference between optimal steps and model steps are 25
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 94 with total number of rewards: -5, total steps100, the average reward per action: -0.04999999999995, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 95 with total number of rewards: 6, total steps80, the average reward per action: 0.07499999999990625, and difference between optimal steps and model steps are 58
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 96 with total number of rewards: 5, total steps100, the average reward per action: 0.04999999999995, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 97 with total number of rewards: 14, total steps58, the average reward per action: 0.2413793103444114, and difference between optimal steps and model steps are 36
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 98 with total number of rewards: 5, total steps100, the average reward per action: 0.04999999999995, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 99 with total number of rewards: 1, total steps100, the average reward per action: 0.00999999999999, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 100 with total number of rewards: -13, total steps100, the average reward per action: -0.12999999999987, and difference between optimal steps and model steps are 78
number of tree 1 at positions  [(0, 9)] at Config 0 at episode 101 with total number of rewards: 15, total steps69, the average reward per action: 0.21739130434751103, and difference between optimal steps and model steps are 47
